Explainable AI for Early Heart Disease Risk Prediction

Temporal â€¢ Interpretable â€¢ Fair â€¢ Clinically Grounded

ğŸ“Œ Overview

This project presents a comprehensive Explainable Artificial Intelligence (XAI) framework for early heart disease risk prediction.
Unlike traditional black-box machine learning models, this system emphasizes interpretability, temporal risk evolution, fairness, uncertainty awareness, and clinical decision support.

The framework is designed to bridge the gap between high predictive performance and real-world clinical usability, making it suitable for academic research, clinical decision-support prototyping, and PhD-level experimentation.

ğŸ¯ Key Objectives

Predict early heart disease risk using structured clinical data

Model temporal risk progression over time

Provide global, local, and counterfactual explanations

Evaluate fairness and bias across demographic subgroups

Quantify uncertainty and confidence intervals

Simulate clinical decision workflows and healthcare policies

Ensure ethical and responsible AI deployment

ğŸ§  Core Contributions

âœ… Unified framework combining prediction + explainability + ethics

âœ… Temporal modeling of cardiovascular risk

âœ… Multi-level explainability (global, local, temporal, counterfactual)

âœ… Cost-sensitive and decision-curveâ€“based clinical evaluation

âœ… Human-in-the-loop and rejection-based safety mechanisms

âœ… Policy and causal proxy analysis for real-world deployment

ğŸ“‚ Project Structure
.
â”œâ”€â”€ README.md
â”œâ”€â”€ run_pipeline.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ data/
â”‚   â””â”€â”€ heart_disease.csv
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/
â”‚   â””â”€â”€ plots/
â”‚       â”œâ”€â”€ *.png
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ evaluate.py
â”‚   â”œâ”€â”€ explainability.py
â”‚   â”œâ”€â”€ clinical_flow.py
â”‚   â”œâ”€â”€ clinical_risk.py
â”‚   â”œâ”€â”€ temporal_risk.py
â”‚   â”œâ”€â”€ fairness_analysis.py
â”‚   â”œâ”€â”€ counterfactual_analysis.py
â”‚   â”œâ”€â”€ policy_simulation.py
â”‚   â”œâ”€â”€ ethical_risk.py
â”‚   â”œâ”€â”€ causal_proxy.py
â”‚   â”œâ”€â”€ bootstrap_performance.py
â”‚   â”œâ”€â”€ ablation_study.py
â”‚   â”œâ”€â”€ confidence_intervals.py
â”‚   â”œâ”€â”€ explanation_stability.py
â”‚   â”œâ”€â”€ explanation_temporal.py
â”‚   â””â”€â”€ ...

ğŸ“Š Generated Outputs

The pipeline generates 35+ publication-ready figures, including:

Predictive performance (ROC, calibration, confidence intervals)

Temporal risk evolution and early warning signals

Global & local explainability (SHAP, feature importance)

Counterfactual explanations

Fairness and subgroup analysis

Cost-sensitive learning effects

Decision curve analysis

Human-AI collaboration analysis

Ethical risk mapping and rejection analysis

Clinical decision flow and policy simulations

All outputs are saved in:

outputs/plots/

âš™ï¸ Installation
1ï¸âƒ£ Create virtual environment (recommended)
python -m venv venv
source venv/bin/activate        # Linux / Mac
venv\Scripts\activate           # Windows

2ï¸âƒ£ Install dependencies
pip install -r requirements.txt

â–¶ï¸ How to Run the Full Pipeline

From the project root directory:

python run_pipeline.py


This will:

Train the predictive model

Evaluate performance metrics

Generate all explainability, fairness, temporal, and policy plots

Save all outputs automatically

You should see console logs confirming successful execution of each module.

ğŸ“ Methodology Summary
ğŸ”¹ Problem Formulation

Binary classification with temporal extensions

Objective: risk prediction + interpretability

ğŸ”¹ Modeling

Supervised ML for structured clinical data

Temporal risk modeling across simulated time steps

ğŸ”¹ Explainability

Global explanations (feature importance, SHAP)

Local explanations (patient-level attribution)

Counterfactual reasoning

Temporal explanation consistency

ğŸ”¹ Evaluation

Accuracy, ROC-AUC, calibration

Decision Curve Analysis (clinical benefit)

Bootstrap stability and ablation studies

ğŸ”¹ Ethics & Safety

Fairness analysis across age and gender

Uncertainty quantification and rejection analysis

Ethical risk visualization

ğŸ§ª Reproducibility

All figures are generated from a single trained model

Deterministic pipeline execution

Modular design for easy extension

Suitable for conference, journal, and PhD evaluation

ğŸ¥ Clinical Relevance

The framework is designed to reflect real clinical workflows, including:

Risk stratification

Human oversight under uncertainty

Policy-level decision simulations

Ethical and regulatory considerations

This makes it well-suited for clinical decision-support research and translational AI studies.

ğŸš€ Future Extensions

Integration with real Electronic Health Records (EHRs)

Multimodal data (imaging, wearables, clinical notes)

Prospective clinical validation

Deployment as a decision-support dashboard

ğŸ“„ Research Paper

A full research paper has been written alongside this project, including:

Structured Introduction with citations

Literature Review table

Extensive Results & Explainability analysis

Ethical, causal, and policy discussions

ğŸ™ Acknowledgements

This work builds upon open-source machine learning libraries and publicly available clinical datasets. The authors acknowledge the broader research community for advancing reproducible and ethical AI in healthcare.

ğŸ“¬ Contact

For academic collaboration, questions, or extensions:

Author: Swarajaya Singh Sawant
Email: swarajayasawant19@gmail.com